{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment_Analysis_NLP.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNxazbfFIYkGx9fembZR1sw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prawizard/TweetsClassification_NLP/blob/main/TweetEval/Sentiment_Analysis_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zxm9gIFFi02"
      },
      "source": [
        "# Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pD7oNRf_BCiU"
      },
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import urllib.request\n",
        "import nltk\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import SnowballStemmer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.metrics import f1_score\n",
        "import requests\n",
        "import collections"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgN_9rGQyena"
      },
      "source": [
        "\n",
        "import os, string, collections\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import snowballstemmer\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
        "from sklearn import metrics\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential, Model, load_model\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.layers import Flatten, Dense, Dropout, Convolution1D, MaxPooling1D, SpatialDropout1D, Input \n",
        "from keras.layers import GlobalMaxPooling1D, concatenate, LSTM, Bidirectional\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import np_utils\n",
        "from keras.callbacks import ModelCheckpoint"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDKThEBPVrEE"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,Flatten,Embedding,Activation, Dropout\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, GlobalMaxPooling1D \n",
        "import numpy as np\n",
        "from numpy import array\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GT7sQy4ZFttE"
      },
      "source": [
        "# Constants"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MlB9kkYFFotD"
      },
      "source": [
        "TRAIN_TEXT_URL=\"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/offensive/train_text.txt\"\n",
        "TRAIN_LABELS_URL=\"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/offensive/train_labels.txt\"\n",
        "VAL_TEXT_URL=\"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/offensive/val_text.txt\"\n",
        "VAL_LABELS_URL=\"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/offensive/val_labels.txt\"\n",
        "TEST_TEXT_URL=\"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/offensive/test_text.txt\"\n",
        "TEST_LABELS_URL=\"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/offensive/test_labels.txt\"\n",
        "VOCAB_SIZE=2000"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igvM4blPFz8b"
      },
      "source": [
        "# Access Data from the Files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhTRYuieF-LC"
      },
      "source": [
        "## Download the .txt files to our runtime"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3eP1mSZRFpBF",
        "outputId": "30c61a47-eae0-4de5-cf15-d12cc5b52af4"
      },
      "source": [
        "r = requests.get(TRAIN_TEXT_URL, allow_redirects=True)\n",
        "open('train_text.txt', 'wb').write(r.content)\n",
        "\n",
        "r = requests.get(TRAIN_LABELS_URL, allow_redirects=True)\n",
        "open('train_labels.txt', 'wb').write(r.content)\n",
        "\n",
        "r = requests.get(VAL_TEXT_URL, allow_redirects=True)\n",
        "open('val_text.txt', 'wb').write(r.content)\n",
        "\n",
        "r = requests.get(VAL_LABELS_URL, allow_redirects=True)\n",
        "open('val_labels.txt', 'wb').write(r.content)\n",
        "\n",
        "r = requests.get(TEST_TEXT_URL, allow_redirects=True)\n",
        "open('test_text.txt', 'wb').write(r.content)\n",
        "\n",
        "r = requests.get(TEST_LABELS_URL, allow_redirects=True)\n",
        "open('test_labels.txt', 'wb').write(r.content)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1720"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgJlnjLsGPHE"
      },
      "source": [
        "## Read data from the files downloaded"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewS1DCGvFpHb"
      },
      "source": [
        "# Tweets\n",
        "stream=open(\"train_text.txt\")\n",
        "tweets=stream.readlines()\n",
        "stream.close()\n",
        "val_stream=open(\"val_text.txt\")\n",
        "val_tweets=val_stream.readlines()\n",
        "val_stream.close()\n",
        "test_stream=open(\"test_text.txt\")\n",
        "test_tweets=test_stream.readlines()\n",
        "test_stream.close()\n",
        "\n",
        "# Labels\n",
        "stream=open(\"train_labels.txt\")\n",
        "tweetsLabels=stream.readlines()\n",
        "stream.close()\n",
        "val_stream=open(\"val_labels.txt\")\n",
        "val_tweetsLabels=val_stream.readlines()\n",
        "val_stream.close()\n",
        "test_stream=open(\"test_labels.txt\")\n",
        "test_tweetsLabels=test_stream.readlines()\n",
        "test_stream.close()\n",
        "\n",
        "\n",
        "# Labels\n",
        "labels=[0]*len(tweetsLabels)\n",
        "for i in range(len(tweetsLabels)):\n",
        "  if tweetsLabels[i].find('\\n')!=-1:\n",
        "    labels[i]=int(re.sub('\\n', '', tweetsLabels[i]))\n",
        "val_labels=[0]*len(val_tweetsLabels)\n",
        "for i in range(len(val_tweetsLabels)):\n",
        "  if val_tweetsLabels[i].find('\\n')!=-1:\n",
        "    val_labels[i]=int(re.sub('\\n', '', val_tweetsLabels[i]))\n",
        "test_labels=[0]*len(test_tweetsLabels)\n",
        "for i in range(len(test_tweetsLabels)):\n",
        "  if test_tweetsLabels[i].find('\\n')!=-1:\n",
        "    test_labels[i]=int(re.sub('\\n', '', test_tweetsLabels[i]))\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jh8aZrlQFpNM",
        "outputId": "b5e64b9b-33da-4fb4-cb94-9766ce5a0c0a"
      },
      "source": [
        "print('Samples in Training set : ',len(labels),', Validation set : ', len(val_labels),', Test set : ', len(test_labels))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Samples in Training set :  11916 , Validation set :  1324 , Test set :  860\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTbHMhp-JxUk"
      },
      "source": [
        "# Pre-processing of the text in tweets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7z2JpSWKK3b"
      },
      "source": [
        "## Remove the '@User' text parts from tweets\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ND7rNLwzJ5gm"
      },
      "source": [
        "\n",
        "for i in range(len(tweets)):\n",
        "  if tweets[i].find('@user')!=-1:\n",
        "    tweets[i]=re.sub('@user', '', tweets[i])\n",
        "\n",
        "for i in range(len(val_tweets)):\n",
        "  if val_tweets[i].find('@user')!=-1:\n",
        "    val_tweets[i]=re.sub('@user', '', val_tweets[i])\n",
        "\n",
        "for i in range(len(test_tweets)):\n",
        "  if test_tweets[i].find('@user')!=-1:\n",
        "    test_tweets[i]=re.sub('@user', '', test_tweets[i])"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CgqCpZNSKW_0"
      },
      "source": [
        "## Remove hashtags"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3hXCHYWMJ5d7"
      },
      "source": [
        "for i in range(len(tweets)):\n",
        "  if tweets[i].find('#[a-zA-Z]+')!=-1:\n",
        "    tweets[i]=re.sub('#[a-zA-Z]+', '', tweets[i])\n",
        "\n",
        "for i in range(len(val_tweets)):\n",
        "  if val_tweets[i].find('#[a-zA-Z]+')!=-1:\n",
        "    val_tweets[i]=re.sub('#[a-zA-Z]+', '', val_tweets[i])\n",
        "\n",
        "for i in range(len(test_tweets)):\n",
        "  if test_tweets[i].find('#[a-zA-Z]+')!=-1:\n",
        "    test_tweets[i]=re.sub('#[a-zA-Z]+', '', test_tweets[i])"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3lvlpSpLW11"
      },
      "source": [
        "## Remove escape characters, unnecessary characters if present and correct wrongly spelt words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pY-TDJ8WJ5ar"
      },
      "source": [
        "for i in range(len(tweets)):\n",
        "  if tweets[i].find('\\n')!=-1:\n",
        "    tweets[i]=re.sub('\\n', '', tweets[i])\n",
        "\n",
        "for i in range(len(val_tweets)):\n",
        "  if val_tweets[i].find('\\n')!=-1:\n",
        "    val_tweets[i]=re.sub('\\n', '', val_tweets[i])\n",
        "\n",
        "for i in range(len(test_tweets)):\n",
        "  if test_tweets[i].find('\\n')!=-1:\n",
        "    test_tweets[i]=re.sub('\\n', '', test_tweets[i])\n",
        "\n",
        "# Unnecessary dots\n",
        "p='\\.\\.\\.|\\.\\.'\n",
        "\n",
        "for i in range(len(tweets)):\n",
        "  tweets[i]=re.sub(p, '', tweets[i])\n",
        "  tweets[i]=tweets[i].lower()\n",
        "\n",
        "for i in range(len(val_tweets)):\n",
        "  val_tweets[i]=re.sub(p, '', val_tweets[i])\n",
        "  val_tweets[i]=val_tweets[i].lower()\n",
        "\n",
        "for i in range(len(test_tweets)):\n",
        "  test_tweets[i]=re.sub(p, '', test_tweets[i])\n",
        "  test_tweets[i]=test_tweets[i].lower()"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "esgeq0dpAPvc"
      },
      "source": [
        "## Store hashtags to replace after tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_rZyVE3fu3ar"
      },
      "source": [
        "h='#[a-zA-Z]+'\n",
        "hashdict={}\n",
        "for i in range(len(tweets)):\n",
        "  hashtags=re.findall(h, tweets[i])\n",
        "  for w in hashtags:\n",
        "    hashdict[w]=w[1:]\n",
        "\n",
        "for i in range(len(val_tweets)):\n",
        "  hashtags=re.findall(h, val_tweets[i])\n",
        "  for w in hashtags:\n",
        "    hashdict[w]=w[1:]\n",
        "\n",
        "for i in range(len(test_tweets)):\n",
        "  hashtags=re.findall(h, test_tweets[i])\n",
        "  for w in hashtags:\n",
        "    hashdict[w]=w[1:]"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjDIz30QH2os"
      },
      "source": [
        "# Make a data frame for the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XggXcvA0FpSb"
      },
      "source": [
        "rows=[]\n",
        "rowIndices=[]\n",
        "for i in range(len(tweets)):\n",
        "  rows.append({\"TWEET\":tweets[i], \"CATEGORY\":labels[i]})\n",
        "  rowIndices.append(i+1)\n",
        "df=pd.DataFrame(rows, index=rowIndices)\n",
        "\n",
        "val_rows=[]\n",
        "val_rowIndices=[]\n",
        "for i in range(len(val_tweets)):\n",
        "  val_rows.append({\"TWEET\":val_tweets[i], \"CATEGORY\":val_labels[i]})\n",
        "  val_rowIndices.append(i+1)\n",
        "val_df=pd.DataFrame(val_rows, index=val_rowIndices)\n",
        "\n",
        "test_rows=[]\n",
        "test_rowIndices=[]\n",
        "for i in range(len(test_tweets)):\n",
        "  test_rows.append({\"TWEET\":test_tweets[i], \"CATEGORY\":test_labels[i]})\n",
        "  test_rowIndices.append(i+1)\n",
        "test_df=pd.DataFrame(test_rows, index=test_rowIndices)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "NTpU1GDfFpW8",
        "outputId": "18b8bcf8-37a9-49df-eee7-2b91b7ca929d"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TWEET</th>\n",
              "      <th>CATEGORY</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>bono who cares. soon people will understand t...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>eight years the republicans denied obama’s pi...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>get him some line help. he is gonna be just f...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>she is great. hi fiona!</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>she has become a parody unto herself? she has...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               TWEET  CATEGORY\n",
              "1   bono who cares. soon people will understand t...         0\n",
              "2   eight years the republicans denied obama’s pi...         1\n",
              "3   get him some line help. he is gonna be just f...         0\n",
              "4                           she is great. hi fiona!          0\n",
              "5   she has become a parody unto herself? she has...         1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "bbF58tUSFpbT",
        "outputId": "3a21c6d8-c334-48ff-f7fd-89fa42040512"
      },
      "source": [
        "val_df.head()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TWEET</th>\n",
              "      <th>CATEGORY</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>wiiu is not even a real console.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>if he is from az i would put my money on se...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>i thought canada had strict gun control.  hel...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>following all #maga patriots p...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1 minute of truth: gun control via</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               TWEET  CATEGORY\n",
              "1                  wiiu is not even a real console.          0\n",
              "2     if he is from az i would put my money on se...         1\n",
              "3   i thought canada had strict gun control.  hel...         0\n",
              "4                  following all #maga patriots p...         0\n",
              "5               1 minute of truth: gun control via           0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "GahQwAq0MOKj",
        "outputId": "82ce2506-d4eb-4207-b770-3edd3f3c649a"
      },
      "source": [
        "test_df.head()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TWEET</th>\n",
              "      <th>CATEGORY</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>#ibelieveblaseyford is liar she is fat ugly li...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>i got in a pretty deep debate with my frien...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>if you want more shootings and more death, the...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>angels now have 6 runs. five of them have come...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>#travel #movies and unix #fortune combined  vi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               TWEET  CATEGORY\n",
              "1  #ibelieveblaseyford is liar she is fat ugly li...         1\n",
              "2     i got in a pretty deep debate with my frien...         0\n",
              "3  if you want more shootings and more death, the...         0\n",
              "4  angels now have 6 runs. five of them have come...         0\n",
              "5  #travel #movies and unix #fortune combined  vi...         0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ne4r8kmZW3oq"
      },
      "source": [
        "# Download stopwords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uaI2kL4DQV4y",
        "outputId": "0fd392bf-d373-496f-dbdd-3be383e409b9"
      },
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWJBcNp2W_Yz"
      },
      "source": [
        "# Tokenize the tweets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WVh1RFWwQrrD"
      },
      "source": [
        "rows=[]\n",
        "rowIndices=[]\n",
        "df_tweets=np.array(df.TWEET)\n",
        "sym=['#','$','?','@','%','^','!','&',',','.','/',\"'\",'`','``',\"''\",'(',')']\n",
        "for i in range(len(df_tweets)):\n",
        "  tokens=word_tokenize(df_tweets[i])\n",
        "  for x in range(len(tokens)):\n",
        "    if tokens[x]=='ca':\n",
        "      tokens[x]='can'\n",
        "    if tokens[x]==\"n't\":\n",
        "      tokens[x]='not'\n",
        "  tokens=[token for token in tokens if token not in sym]\n",
        "  rows.append({\"TWEET\":tokens, \"CATEGORY\":labels[i]})\n",
        "  rowIndices.append(i+1)\n",
        "tokenized_df=pd.DataFrame(rows, index=rowIndices)\n",
        "\n",
        "val_rows=[]\n",
        "val_rowIndices=[]\n",
        "val_df_tweets=np.array(val_df.TWEET)\n",
        "for i in range(len(val_df_tweets)):\n",
        "  val_tokens=word_tokenize(val_df_tweets[i])\n",
        "  for x in range(len(val_tokens)):\n",
        "    if val_tokens[x]=='ca':\n",
        "      val_tokens[x]='can'\n",
        "    if val_tokens[x]==\"n't\":\n",
        "      val_tokens[x]='not'\n",
        "  val_tokens=[token for token in val_tokens if token not in sym]\n",
        "  val_rows.append({\"TWEET\":val_tokens, \"CATEGORY\":val_labels[i]})\n",
        "  val_rowIndices.append(i+1)\n",
        "tokenized_val_df=pd.DataFrame(val_rows, index=val_rowIndices)\n",
        "\n",
        "test_rows=[]\n",
        "test_rowIndices=[]\n",
        "test_df_tweets=np.array(test_df.TWEET)\n",
        "for i in range(len(test_df_tweets)):\n",
        "  test_tokens=word_tokenize(test_df_tweets[i])\n",
        "  for x in range(len(test_tokens)):\n",
        "    if test_tokens[x]=='ca':\n",
        "      test_tokens[x]='can'\n",
        "    if test_tokens[x]==\"n't\":\n",
        "      test_tokens[x]='not'\n",
        "  test_tokens=[token for token in test_tokens if token not in sym]\n",
        "  test_rows.append({\"TWEET\":test_tokens, \"CATEGORY\":test_labels[i]})\n",
        "  test_rowIndices.append(i+1)\n",
        "tokenized_test_df=pd.DataFrame(test_rows, index=test_rowIndices)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "p7ZH4Q3JR7cQ",
        "outputId": "98e01e26-bf68-413f-de58-4c3bad1a47a1"
      },
      "source": [
        "tokenized_df.head()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TWEET</th>\n",
              "      <th>CATEGORY</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[bono, who, cares, soon, people, will, underst...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[eight, years, the, republicans, denied, obama...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[get, him, some, line, help, he, is, gon, na, ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[she, is, great, hi, fiona]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>[she, has, become, a, parody, unto, herself, s...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               TWEET  CATEGORY\n",
              "1  [bono, who, cares, soon, people, will, underst...         0\n",
              "2  [eight, years, the, republicans, denied, obama...         1\n",
              "3  [get, him, some, line, help, he, is, gon, na, ...         0\n",
              "4                        [she, is, great, hi, fiona]         0\n",
              "5  [she, has, become, a, parody, unto, herself, s...         1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "tB408lodS-7w",
        "outputId": "58b7a298-f6bd-4eed-ec1a-9244cb87d3d9"
      },
      "source": [
        "tokenized_val_df.head()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TWEET</th>\n",
              "      <th>CATEGORY</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[wiiu, is, not, even, a, real, console]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[if, he, is, from, az, i, would, put, my, mone...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[i, thought, canada, had, strict, gun, control...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[following, all, maga, patriots, please, follo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>[1, minute, of, truth, :, gun, control, via]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               TWEET  CATEGORY\n",
              "1            [wiiu, is, not, even, a, real, console]         0\n",
              "2  [if, he, is, from, az, i, would, put, my, mone...         1\n",
              "3  [i, thought, canada, had, strict, gun, control...         0\n",
              "4  [following, all, maga, patriots, please, follo...         0\n",
              "5       [1, minute, of, truth, :, gun, control, via]         0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "8vLUm1kyS-vR",
        "outputId": "912bf99d-b5a5-4d46-d78f-ba39a675527f"
      },
      "source": [
        "tokenized_test_df.head()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TWEET</th>\n",
              "      <th>CATEGORY</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[ibelieveblaseyford, is, liar, she, is, fat, u...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[i, got, in, a, pretty, deep, debate, with, my...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[if, you, want, more, shootings, and, more, de...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[angels, now, have, 6, runs, five, of, them, h...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>[travel, movies, and, unix, fortune, combined,...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               TWEET  CATEGORY\n",
              "1  [ibelieveblaseyford, is, liar, she, is, fat, u...         1\n",
              "2  [i, got, in, a, pretty, deep, debate, with, my...         0\n",
              "3  [if, you, want, more, shootings, and, more, de...         0\n",
              "4  [angels, now, have, 6, runs, five, of, them, h...         0\n",
              "5  [travel, movies, and, unix, fortune, combined,...         0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxmJNOOcglPe"
      },
      "source": [
        "def update_vocab_counter(row):\n",
        "    for word in row:\n",
        "        vocab_counter[word] += 1"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2LYnqax5806"
      },
      "source": [
        "vocab_counter = collections.Counter()\n",
        "tokenized_df['TWEET'].apply(update_vocab_counter);\n",
        "vocab = sorted(vocab_counter, key=vocab_counter.get, reverse=True)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHORlrR36J14",
        "outputId": "1ae1aa39-0f39-478a-ad60-226c7e66690f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "len(vocab)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20833"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZlrWKZd673A"
      },
      "source": [
        "max_words = 5000"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EUFrIYF1uq4N"
      },
      "source": [
        "w2id = {w:i for i, w in enumerate(vocab[:max_words])}\n",
        "w2id['unk'] = -1"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Us0iocDuu7M"
      },
      "source": [
        "def transform_to_ids(row):\n",
        "    return [w2id[w] if w in w2id else w2id['unk'] for w in row]"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wjk4yEw5u6O0"
      },
      "source": [
        "tokenized_df['tokenized_int'] = tokenized_df['TWEET'].apply(lambda x: transform_to_ids(x))"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2xT4E3FwKwU"
      },
      "source": [
        "tokenized_val_df['tokenized_int'] = tokenized_val_df['TWEET'].apply(lambda x: transform_to_ids(x))\n",
        "tokenized_test_df['tokenized_int'] = tokenized_test_df['TWEET'].apply(lambda x: transform_to_ids(x))"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfBzUzcJvSQr",
        "outputId": "eeb092b4-6cff-4603-cc50-af50528a15f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "tokenized_df.head()"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TWEET</th>\n",
              "      <th>CATEGORY</th>\n",
              "      <th>tokenized_int</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[bono, who, cares, soon, people, will, underst...</td>\n",
              "      <td>0</td>\n",
              "      <td>[1225, 45, 683, 568, 49, 47, 312, 10, 19, 1813...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[eight, years, the, republicans, denied, obama...</td>\n",
              "      <td>1</td>\n",
              "      <td>[4712, 159, 0, 286, 4713, 252, 14, 37, 3337, -...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[get, him, some, line, help, he, is, gon, na, ...</td>\n",
              "      <td>0</td>\n",
              "      <td>[66, 74, 114, 471, 195, 9, 1, 384, 269, 22, 42...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[she, is, great, hi, fiona]</td>\n",
              "      <td>0</td>\n",
              "      <td>[15, 1, 152, 1344, 4714]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>[she, has, become, a, parody, unto, herself, s...</td>\n",
              "      <td>1</td>\n",
              "      <td>[15, 59, 413, 4, -1, -1, 728, 15, 59, 1345, 94...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               TWEET  ...                                      tokenized_int\n",
              "1  [bono, who, cares, soon, people, will, underst...  ...  [1225, 45, 683, 568, 49, 47, 312, 10, 19, 1813...\n",
              "2  [eight, years, the, republicans, denied, obama...  ...  [4712, 159, 0, 286, 4713, 252, 14, 37, 3337, -...\n",
              "3  [get, him, some, line, help, he, is, gon, na, ...  ...  [66, 74, 114, 471, 195, 9, 1, 384, 269, 22, 42...\n",
              "4                        [she, is, great, hi, fiona]  ...                           [15, 1, 152, 1344, 4714]\n",
              "5  [she, has, become, a, parody, unto, herself, s...  ...  [15, 59, 413, 4, -1, -1, 728, 15, 59, 1345, 94...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpqVbyCGvUYM",
        "outputId": "79973e51-ee4e-4763-a965-b1d76a0b7708",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "lens = tokenized_df['tokenized_int'].apply(lambda x: len(x))\n",
        "min(lens), max(lens), np.mean(lens)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 69, 20.31117824773414)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJfD9LkOf4CW",
        "outputId": "41499d92-d083-44e2-bdc5-248dc23cfb1b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "a=tokenized_df['tokenized_int'].values\n",
        "j=0\n",
        "for i in a:\n",
        "  if len(i)==69:\n",
        "    z=i\n",
        "    k=j\n",
        "  j+=1\n",
        "print(z)\n",
        "print(tokenized_df['TWEET'].values[k])"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[7, 14, 169, 237, 5, 31, 3, 8, 467, 65, 1, 10, 7, 46, 22, 12, 57, 224, -1, 5, 3, 46, 42, 1061, 12, 5, 538, 65, 51, 10, 14, 37, 11, 13, 139, 14, 37, 504, 4, 1377, 781, 104, 360, 7, 14, 169, 0, 495, 17, 3622, 7, 298, 59, 2, 22, 3028, 153, 21, 107, 35, 7, 47, 22, 54, 0, 272, 1226, 7, 1832]\n",
            "['i', '’', 'm', 'black', 'and', 'what', 'you', 'are', 'telling', 'me', 'is', 'that', 'i', 'can', 'be', 'in', 'my', 'own', 'dwelling', 'and', 'you', 'can', 'just', 'walk', 'in', 'and', 'kill', 'me', 'no', 'that', '’', 's', 'not', 'it', 'let', '’', 's', 'run', 'a', 'smear', 'campaign', 'even', 'though', 'i', '’', 'm', 'the', 'victim', 'this', 'rage', 'i', 'feel', 'has', 'to', 'be', 'settled', 'down', 'with', 'love', 'but', 'i', 'will', 'be', 'at', 'the', 'next', 'rally', 'i', 'promise']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9CpRnKdkvjSc"
      },
      "source": [
        "maxlen = 70"
      ],
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VVY5Rp5xxfrp"
      },
      "source": [
        "X_train=tokenized_df['tokenized_int'].values\n",
        "X_test=tokenized_test_df['tokenized_int'].values\n",
        "y_train=tokenized_df['CATEGORY'].values\n",
        "y_test=tokenized_test_df['CATEGORY'].values"
      ],
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8axza5eyMXj"
      },
      "source": [
        "x_train = pad_sequences(X_train, maxlen=maxlen, value=-1)\n",
        "x_test = pad_sequences(X_test, maxlen=maxlen, value=-1)"
      ],
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5iBHD31yWFE"
      },
      "source": [
        "dummy_y = np_utils.to_categorical(y_train)\n",
        "dummy_y_test = np_utils.to_categorical(y_test)"
      ],
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPVY_qBEzFyK"
      },
      "source": [
        "def baseline_model():\n",
        "    model = Sequential([Embedding(input_dim=max_words, output_dim=50, input_length=maxlen),\n",
        "                        Flatten(),\n",
        "                        Dense(2, activation='softmax')])\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ZnhIifCzPrb"
      },
      "source": [
        "estimator = KerasClassifier(build_fn=baseline_model, epochs=5, batch_size=100, verbose=0)\n",
        "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)"
      ],
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4SdkZhgzXE8"
      },
      "source": [
        ""
      ],
      "execution_count": 76,
      "outputs": []
    }
  ]
}