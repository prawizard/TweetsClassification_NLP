{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment_Analysis_NLP_Progress.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prawizard/TweetsClassification_NLP/blob/main/TweetEval/Sentiment_Analysis_NLP_Progress.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zxm9gIFFi02"
      },
      "source": [
        "# Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pD7oNRf_BCiU"
      },
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import urllib.request\n",
        "import nltk\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import SnowballStemmer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.metrics import f1_score\n",
        "import requests\n",
        "import collections"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgN_9rGQyena"
      },
      "source": [
        "\n",
        "import os, string, collections\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import snowballstemmer\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
        "from sklearn import metrics\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential, Model, load_model\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.layers import Flatten, Dense, Dropout, Convolution1D, MaxPooling1D, SpatialDropout1D, Input \n",
        "from keras.layers import GlobalMaxPooling1D, concatenate, LSTM, Bidirectional\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import np_utils\n",
        "from keras.callbacks import ModelCheckpoint"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDKThEBPVrEE"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,Flatten,Embedding,Activation, Dropout\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, GlobalMaxPooling1D \n",
        "import numpy as np\n",
        "from numpy import array\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GT7sQy4ZFttE"
      },
      "source": [
        "# Constants"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MlB9kkYFFotD"
      },
      "source": [
        "TRAIN_TEXT_URL=\"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/offensive/train_text.txt\"\n",
        "TRAIN_LABELS_URL=\"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/offensive/train_labels.txt\"\n",
        "VAL_TEXT_URL=\"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/offensive/val_text.txt\"\n",
        "VAL_LABELS_URL=\"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/offensive/val_labels.txt\"\n",
        "TEST_TEXT_URL=\"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/offensive/test_text.txt\"\n",
        "TEST_LABELS_URL=\"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/offensive/test_labels.txt\"\n",
        "VOCAB_SIZE=2000"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igvM4blPFz8b"
      },
      "source": [
        "# Access Data from the Files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhTRYuieF-LC"
      },
      "source": [
        "## Download the .txt files to our runtime"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3eP1mSZRFpBF",
        "outputId": "1a6317a9-c59b-4a7f-ca9d-0b595b5475d0"
      },
      "source": [
        "r = requests.get(TRAIN_TEXT_URL, allow_redirects=True)\n",
        "open('train_text.txt', 'wb').write(r.content)\n",
        "\n",
        "r = requests.get(TRAIN_LABELS_URL, allow_redirects=True)\n",
        "open('train_labels.txt', 'wb').write(r.content)\n",
        "\n",
        "r = requests.get(VAL_TEXT_URL, allow_redirects=True)\n",
        "open('val_text.txt', 'wb').write(r.content)\n",
        "\n",
        "r = requests.get(VAL_LABELS_URL, allow_redirects=True)\n",
        "open('val_labels.txt', 'wb').write(r.content)\n",
        "\n",
        "r = requests.get(TEST_TEXT_URL, allow_redirects=True)\n",
        "open('test_text.txt', 'wb').write(r.content)\n",
        "\n",
        "r = requests.get(TEST_LABELS_URL, allow_redirects=True)\n",
        "open('test_labels.txt', 'wb').write(r.content)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1720"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgJlnjLsGPHE"
      },
      "source": [
        "## Read data from the files downloaded"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewS1DCGvFpHb"
      },
      "source": [
        "# Tweets\n",
        "stream=open(\"train_text.txt\")\n",
        "tweets=stream.readlines()\n",
        "stream.close()\n",
        "val_stream=open(\"val_text.txt\")\n",
        "val_tweets=val_stream.readlines()\n",
        "val_stream.close()\n",
        "test_stream=open(\"test_text.txt\")\n",
        "test_tweets=test_stream.readlines()\n",
        "test_stream.close()\n",
        "\n",
        "# Labels\n",
        "stream=open(\"train_labels.txt\")\n",
        "tweetsLabels=stream.readlines()\n",
        "stream.close()\n",
        "val_stream=open(\"val_labels.txt\")\n",
        "val_tweetsLabels=val_stream.readlines()\n",
        "val_stream.close()\n",
        "test_stream=open(\"test_labels.txt\")\n",
        "test_tweetsLabels=test_stream.readlines()\n",
        "test_stream.close()\n",
        "\n",
        "\n",
        "# Labels\n",
        "labels=[0]*len(tweetsLabels)\n",
        "for i in range(len(tweetsLabels)):\n",
        "  if tweetsLabels[i].find('\\n')!=-1:\n",
        "    labels[i]=int(re.sub('\\n', '', tweetsLabels[i]))\n",
        "val_labels=[0]*len(val_tweetsLabels)\n",
        "for i in range(len(val_tweetsLabels)):\n",
        "  if val_tweetsLabels[i].find('\\n')!=-1:\n",
        "    val_labels[i]=int(re.sub('\\n', '', val_tweetsLabels[i]))\n",
        "test_labels=[0]*len(test_tweetsLabels)\n",
        "for i in range(len(test_tweetsLabels)):\n",
        "  if test_tweetsLabels[i].find('\\n')!=-1:\n",
        "    test_labels[i]=int(re.sub('\\n', '', test_tweetsLabels[i]))\n"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jh8aZrlQFpNM",
        "outputId": "567633d5-f84f-4ab3-a3de-f6815380d7a4"
      },
      "source": [
        "print('Samples in Training set : ',len(labels),', Validation set : ', len(val_labels),', Test set : ', len(test_labels))"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Samples in Training set :  11916 , Validation set :  1324 , Test set :  860\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTbHMhp-JxUk"
      },
      "source": [
        "# Pre-processing of the text in tweets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7z2JpSWKK3b"
      },
      "source": [
        "## Remove the '@User' text parts from tweets\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ND7rNLwzJ5gm"
      },
      "source": [
        "\n",
        "for i in range(len(tweets)):\n",
        "  if tweets[i].find('@user')!=-1:\n",
        "    tweets[i]=re.sub('@user', '', tweets[i])\n",
        "\n",
        "for i in range(len(val_tweets)):\n",
        "  if val_tweets[i].find('@user')!=-1:\n",
        "    val_tweets[i]=re.sub('@user', '', val_tweets[i])\n",
        "\n",
        "for i in range(len(test_tweets)):\n",
        "  if test_tweets[i].find('@user')!=-1:\n",
        "    test_tweets[i]=re.sub('@user', '', test_tweets[i])"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CgqCpZNSKW_0"
      },
      "source": [
        "## Remove hashtags"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3hXCHYWMJ5d7"
      },
      "source": [
        "for i in range(len(tweets)):\n",
        "  if tweets[i].find('#[a-zA-Z]+')!=-1:\n",
        "    tweets[i]=re.sub('#[a-zA-Z]+', '', tweets[i])\n",
        "\n",
        "for i in range(len(val_tweets)):\n",
        "  if val_tweets[i].find('#[a-zA-Z]+')!=-1:\n",
        "    val_tweets[i]=re.sub('#[a-zA-Z]+', '', val_tweets[i])\n",
        "\n",
        "for i in range(len(test_tweets)):\n",
        "  if test_tweets[i].find('#[a-zA-Z]+')!=-1:\n",
        "    test_tweets[i]=re.sub('#[a-zA-Z]+', '', test_tweets[i])"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3lvlpSpLW11"
      },
      "source": [
        "## Remove escape characters, unnecessary characters if present and correct wrongly spelt words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pY-TDJ8WJ5ar"
      },
      "source": [
        "for i in range(len(tweets)):\n",
        "  if tweets[i].find('\\n')!=-1:\n",
        "    tweets[i]=re.sub('\\n', '', tweets[i])\n",
        "\n",
        "for i in range(len(val_tweets)):\n",
        "  if val_tweets[i].find('\\n')!=-1:\n",
        "    val_tweets[i]=re.sub('\\n', '', val_tweets[i])\n",
        "\n",
        "for i in range(len(test_tweets)):\n",
        "  if test_tweets[i].find('\\n')!=-1:\n",
        "    test_tweets[i]=re.sub('\\n', '', test_tweets[i])\n",
        "\n",
        "# Unnecessary dots\n",
        "p='\\.\\.\\.|\\.\\.'\n",
        "\n",
        "for i in range(len(tweets)):\n",
        "  tweets[i]=re.sub(p, '', tweets[i])\n",
        "  tweets[i]=tweets[i].lower()\n",
        "\n",
        "for i in range(len(val_tweets)):\n",
        "  val_tweets[i]=re.sub(p, '', val_tweets[i])\n",
        "  val_tweets[i]=val_tweets[i].lower()\n",
        "\n",
        "for i in range(len(test_tweets)):\n",
        "  test_tweets[i]=re.sub(p, '', test_tweets[i])\n",
        "  test_tweets[i]=test_tweets[i].lower()"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPK6DFYJai3p"
      },
      "source": [
        "rows=[]\n",
        "rowIndices=[]\n",
        "for i in range(len(tweets)):\n",
        "  rows.append({\"TWEET\":tweets[i], \"CATEGORY\":labels[i]})\n",
        "  rowIndices.append(i+1)\n",
        "train_df=pd.DataFrame(rows, index=rowIndices)\n",
        "\n",
        "val_rows=[]\n",
        "val_rowIndices=[]\n",
        "for i in range(len(val_tweets)):\n",
        "  val_rows.append({\"TWEET\":val_tweets[i], \"CATEGORY\":val_labels[i]})\n",
        "  val_rowIndices.append(i+1)\n",
        "val_df=pd.DataFrame(val_rows, index=val_rowIndices)\n",
        "\n",
        "test_rows=[]\n",
        "test_rowIndices=[]\n",
        "for i in range(len(test_tweets)):\n",
        "  test_rows.append({\"TWEET\":test_tweets[i], \"CATEGORY\":test_labels[i]})\n",
        "  test_rowIndices.append(i+1)\n",
        "test_df=pd.DataFrame(test_rows, index=test_rowIndices)"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MstYIClUev7S"
      },
      "source": [
        "frames=[train_df, val_df, test_df]\n",
        "df=pd.concat(frames)"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nC7x0RmBaiyJ",
        "outputId": "a087e446-d811-4666-9d7c-70be540a73de"
      },
      "source": [
        "type(df)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.frame.DataFrame"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "cXse8yQ8aiva",
        "outputId": "083a44a4-3ca7-485e-803c-304c63e0f8d7"
      },
      "source": [
        "df"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TWEET</th>\n",
              "      <th>CATEGORY</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>bono who cares. soon people will understand t...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>eight years the republicans denied obama’s pi...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>get him some line help. he is gonna be just f...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>she is great. hi fiona!</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>she has become a parody unto herself? she has...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>856</th>\n",
              "      <td>#cnn irrationally argues 4 legalising #abortio...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>857</th>\n",
              "      <td>city of chicago, democrat run wi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>858</th>\n",
              "      <td>#conservatives don’t care what you postit’s  p...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>859</th>\n",
              "      <td>#antifa #resist trump is trying to bring world...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>860</th>\n",
              "      <td>#maine you need to face facts  doesn’t really ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>14100 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 TWEET  CATEGORY\n",
              "1     bono who cares. soon people will understand t...         0\n",
              "2     eight years the republicans denied obama’s pi...         1\n",
              "3     get him some line help. he is gonna be just f...         0\n",
              "4                             she is great. hi fiona!          0\n",
              "5     she has become a parody unto herself? she has...         1\n",
              "..                                                 ...       ...\n",
              "856  #cnn irrationally argues 4 legalising #abortio...         0\n",
              "857                city of chicago, democrat run wi...         0\n",
              "858  #conservatives don’t care what you postit’s  p...         1\n",
              "859  #antifa #resist trump is trying to bring world...         0\n",
              "860  #maine you need to face facts  doesn’t really ...         0\n",
              "\n",
              "[14100 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bwk0QJELaisS",
        "outputId": "bf1bdcc3-e7d9-4693-ef0d-708049c9cb4d"
      },
      "source": [
        "df['CATEGORY'].value_counts()"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    9460\n",
              "1    4640\n",
              "Name: CATEGORY, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GaFjjNEdaikK",
        "outputId": "27810121-e65e-498b-ff0f-e73e319d787f"
      },
      "source": [
        "text = df['TWEET'].tolist()\n",
        "text[:10]"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[' bono who cares. soon people will understand that they gain nothing from following a phony celebrity. become a leader of your people instead or help and support your fellow countrymen. ',\n",
              " ' eight years the republicans denied obama’s picks. breitbarters outrage is as phony as their fake president. ',\n",
              " ' get him some line help. he is gonna be just fine. as the game went on you could see him progressing more with his reads. he brought what has been missing. the deep ball presence. now he just needs a little more time ',\n",
              " '  she is great. hi fiona! ',\n",
              " \" she has become a parody unto herself? she has certainly taken some heat for being such an.well idiot. could be optic too  who know with liberals  they're all optics.  no substance \",\n",
              " '               this is the vetsresistsquadron\"\" is bullshit they are girl scout veterans, i have never met any other veterans or served with anyone that was a gun control advocate? have you?\"\" ',\n",
              " ' your looking more like a plant #maga #walkaway ',\n",
              " '  lol. except he’s the most successful president in our lifetimes. he’s undone most of the damage obummer did and set america on the right path again. #maga ',\n",
              " ' been a willie fan since before most of you were born.love that he is holding a rally with beto. exactly which fans are furious?  could you give some specifics? ',\n",
              " \" here's a link to my channel with a plethora of topics to peruse: \"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9EYIcwqdLd-"
      },
      "source": [
        "y = df['CATEGORY']"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ZvX83DbdLjq",
        "outputId": "d581fd10-f8f3-48da-8a54-7357f390d249"
      },
      "source": [
        "token = Tokenizer()\n",
        "token.fit_on_texts(text)\n",
        "token"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras_preprocessing.text.Tokenizer at 0x7f1d67e76e10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oeT9J6pfdLqK",
        "outputId": "17dc866b-e809-46d8-c27d-f6717822f843"
      },
      "source": [
        "vocab_size = len(token.word_index) + 1\n",
        "vocab_size"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23433"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nek6_FDzdLwT",
        "outputId": "91472ffc-aab2-4153-ae15-c7381238c6d7"
      },
      "source": [
        "import itertools \n",
        "print(dict(itertools.islice(token.index_word.items(), 100)))"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{1: 'the', 2: 'is', 3: 'to', 4: 'a', 5: 'and', 6: 'you', 7: 'of', 8: 'are', 9: 'i', 10: 'he', 11: 'in', 12: 'that', 13: 'for', 14: 'she', 15: 'it', 16: 'this', 17: 'on', 18: 'not', 19: 'with', 20: 'they', 21: 'have', 22: 'be', 23: 'liberals', 24: 'gun', 25: 'so', 26: 'all', 27: 'control', 28: 'antifa', 29: 'your', 30: 'like', 31: 'what', 32: 'as', 33: 'but', 34: 'we', 35: 'just', 36: 'about', 37: 'her', 38: 'maga', 39: 'was', 40: 'if', 41: 'conservatives', 42: 'will', 43: 'do', 44: 'who', 45: 'people', 46: 'no', 47: 'his', 48: 'at', 49: 'or', 50: 'my', 51: 'by', 52: 'has', 53: 'from', 54: 'how', 55: 'an', 56: 'out', 57: 'up', 58: 'their', 59: 'me', 60: 'get', 61: 'one', 62: 'amp', 63: 'know', 64: 'trump', 65: 'why', 66: 'when', 67: 'more', 68: 'because', 69: 'can', 70: 'him', 71: 'now', 72: 'them', 73: 'think', 74: \"don't\", 75: 'there', 76: 'would', 77: 'should', 78: 'right', 79: 'our', 80: 'good', 81: 'only', 82: 'us', 83: \"it's\", 84: 'want', 85: 'time', 86: 'go', 87: 'see', 88: 'going', 89: 'need', 90: 'never', 91: 'than', 92: 'shit', 93: 'been', 94: 'being', 95: 'don’t', 96: 'then', 97: 'love', 98: 'even', 99: 'these', 100: 'say'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_7w-lgcdL1t",
        "outputId": "1146df96-649f-4ade-cb98-609d6afba182"
      },
      "source": [
        "x = ['i to the a and']\n",
        "token.texts_to_sequences(x)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[9, 3, 1, 4, 5]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LxGkvfuldL7G",
        "outputId": "2455bf7d-2d61-4eb3-e605-e729bafc5598"
      },
      "source": [
        "encoded_text = token.texts_to_sequences(text)\n",
        "print(encoded_text[:30])"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1370, 44, 694, 532, 45, 42, 324, 12, 20, 1923, 145, 53, 542, 4, 2279, 3978, 437, 4, 660, 7, 29, 45, 480, 49, 182, 5, 159, 29, 1638, 10016], [3979, 147, 1, 263, 4601, 2875, 3980, 10017, 1566, 2, 32, 2279, 32, 58, 285, 135], [60, 70, 107, 543, 182, 10, 2, 415, 22, 35, 517, 32, 1, 298, 544, 17, 6, 154, 87, 70, 10018, 67, 19, 47, 10019, 10, 1125, 31, 52, 93, 1371, 1, 569, 2021, 3501, 71, 10, 35, 224, 4, 287, 67, 85], [14, 2, 138, 1208, 3981], [14, 52, 437, 4, 6990, 10020, 746, 14, 52, 1372, 850, 107, 5520, 13, 94, 188, 55, 117, 570, 154, 22, 10021, 102, 44, 63, 19, 23, 361, 26, 5521, 46, 6991], [16, 2, 1, 10022, 2, 533, 20, 8, 362, 10023, 2022, 9, 21, 90, 1080, 101, 118, 2022, 49, 2639, 19, 213, 12, 39, 4, 24, 27, 1924, 21, 6], [29, 288, 67, 30, 4, 2876, 38, 352], [161, 586, 260, 1, 119, 1253, 135, 11, 79, 10024, 260, 6992, 119, 7, 1, 2133, 10025, 105, 5, 639, 174, 17, 1, 78, 2431, 158, 38], [93, 4, 3127, 649, 220, 204, 119, 7, 6, 110, 1126, 97, 12, 10, 2, 1081, 4, 1209, 19, 951, 368, 185, 980, 8, 1567, 154, 6, 192, 107, 6993], [2280, 4, 1568, 3, 50, 2877, 19, 4, 10026, 7, 3502, 3, 10027], [28, 76, 1425, 4, 41, 397, 128, 5, 599, 76, 22, 75, 10028, 1, 10029, 62, 1639, 2640, 17, 1, 5522], [20, 6994, 1827, 94, 1210, 13, 3982, 10030, 6995, 75, 8, 827, 10031, 2878, 1, 155, 40, 18, 628, 342, 7, 92, 40, 6, 8, 88, 3, 390, 1, 213, 69, 60, 1210, 1496, 1640, 99, 45, 123, 2641, 5523, 5, 5524, 10032], [545, 4602, 554, 2642, 7, 3503, 5, 96, 300, 3, 3128, 112, 24, 27, 450, 197, 1569], [10033], [2643, 77, 21, 93, 1321, 112, 4, 245, 348, 301, 30, 1, 1735, 42, 222, 70, 6996, 1, 3983, 78, 148, 1, 6997, 221, 117], [16, 2, 4, 447, 1082, 53, 23, 5, 113, 294, 3129, 2432, 34, 21, 3, 2879, 1, 650, 184, 4603, 253, 184, 5, 96, 3504, 87, 922, 11, 15, 10034], [123, 10035, 2644, 119, 7, 1, 10036, 1211, 124, 194, 506, 12, 17, 59], [117, 87, 40, 9, 273, 264, 48, 2281, 36, 902, 24, 27, 167, 5, 14, 3984, 59, 49, 775, 59, 4, 3505, 2433, 10037, 2880, 32, 14, 105, 96, 34, 600, 322, 4, 1641, 127, 35, 264, 148, 1, 5525], [6, 241, 1, 103, 523, 1083, 10038, 26, 7, 2023, 2881], [138, 2882, 75, 599, 243, 18, 25, 114, 38, 10039], [6, 8, 25, 10040, 15, 239, 22, 281, 3, 373, 12, 103], [26, 6, 43, 2, 357, 26, 534, 122, 82, 357, 38], [10041, 3985], [10, 123, 10042, 12, 75, 2, 1, 1164, 2134, 66, 34, 8, 2434, 1126, 96, 75, 2, 1, 6998, 2134, 185, 2, 728, 66, 34, 10043, 828, 3, 79, 4604, 6999, 5, 22, 10044, 10045, 160, 94, 7000, 51, 47, 2024, 48, 7001, 66, 79, 4605, 1642, 2, 470, 3506, 187], [65, 8, 6, 2282, 85, 7002, 17, 259, 3986, 17, 2883, 7, 45, 289, 335, 12, 1497, 387, 30, 208, 2, 35, 4, 1007, 10046, 1322, 10047, 3, 118, 5526, 12, 20, 172, 2645, 51, 64], [34, 115, 10048, 2646, 587, 1, 3130, 747, 33, 34, 69, 2647, 729, 13, 66, 10, 1165, 47, 198, 1008, 39, 5527, 10049, 2884, 2283, 54, 36, 1570, 5, 16, 2, 10050, 195, 245, 1040, 5, 10, 2, 1040, 114, 121, 91, 1570], [14, 2, 4, 223, 1426, 9, 178, 37, 25, 114], [10, 2, 25, 3987, 5, 9, 97, 54, 1254, 10, 2, 32, 4, 230], [1166, 34, 639, 96, 291], [10, 2, 4, 10051, 1167, 10]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5TyYMOtpdvYc",
        "outputId": "17791b3b-cdb7-4552-b71d-ed622a62a879"
      },
      "source": [
        "ll=len(encoded_text[0])\n",
        "for tw in encoded_text:\n",
        "  l=len(tw)\n",
        "  if l>ll:\n",
        "    ll=l\n",
        "ll"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "62"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8hQLwOKVdMAf",
        "outputId": "ecdfafdd-8136-49b1-efd3-c63f0fcad314"
      },
      "source": [
        "max_length = 65\n",
        "X = pad_sequences(encoded_text, maxlen=max_length, padding='post')\n",
        "print(X)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1370   44  694 ...    0    0    0]\n",
            " [3979  147    1 ...    0    0    0]\n",
            " [  60   70  107 ...    0    0    0]\n",
            " ...\n",
            " [  41   95  184 ...    0    0    0]\n",
            " [  28  888   64 ...    0    0    0]\n",
            " [9691    6   89 ...    0    0    0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fvtoeqHTdMF5",
        "outputId": "4ef8b101-676d-4a1f-969f-57874b589803"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14100, 65)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IiKGYgHyfwej"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42, test_size = 0.2, stratify = y)"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "059Elzdkfwkg"
      },
      "source": [
        "vec_size = 350\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, vec_size, input_length=max_length))\n",
        "\n",
        "model.add(Conv1D(64, 8, activation = 'relu'))\n",
        "model.add(MaxPooling1D(2))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(16, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(GlobalMaxPooling1D())\n",
        "\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-k_-mQRyfwo9"
      },
      "source": [
        "model.compile(optimizer='adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DdvlqqS_fwsy",
        "outputId": "b1128d24-e0ef-4061-f486-6f084ac9905b"
      },
      "source": [
        "%%time\n",
        "model.fit(X_train, y_train, epochs = 5, validation_data = (X_test, y_test))"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "353/353 [==============================] - 29s 81ms/step - loss: 0.6421 - accuracy: 0.6529 - val_loss: 0.6070 - val_accuracy: 0.7255\n",
            "Epoch 2/5\n",
            "353/353 [==============================] - 28s 80ms/step - loss: 0.4965 - accuracy: 0.7805 - val_loss: 0.5544 - val_accuracy: 0.7379\n",
            "Epoch 3/5\n",
            "353/353 [==============================] - 28s 80ms/step - loss: 0.3290 - accuracy: 0.8720 - val_loss: 0.5540 - val_accuracy: 0.7287\n",
            "Epoch 4/5\n",
            "353/353 [==============================] - 28s 81ms/step - loss: 0.1964 - accuracy: 0.9311 - val_loss: 0.6252 - val_accuracy: 0.7096\n",
            "Epoch 5/5\n",
            "353/353 [==============================] - 28s 80ms/step - loss: 0.1155 - accuracy: 0.9629 - val_loss: 0.6566 - val_accuracy: 0.7319\n",
            "CPU times: user 4min 3s, sys: 5.87 s, total: 4min 9s\n",
            "Wall time: 2min 22s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f1dbb9ca450>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYc-KEDTi2B0"
      },
      "source": [
        "y_pred=(model.predict(X_test)>0.5)*1"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EWyRQH-LuRbt",
        "outputId": "091233de-7367-4fb6-b666-95fbceb8564e"
      },
      "source": [
        "y_pred[:5]"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-jY_ta4tsUq",
        "outputId": "201c89fb-90d4-4dc5-da51-cf358a717d9a"
      },
      "source": [
        "y_true=np.array(y_test)\n",
        "metrics.f1_score(y_true, y_pred, average='macro')\n"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6899005608181348"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tbShJHf8w5pU"
      },
      "source": [
        "# Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydc3cvhuuFyz"
      },
      "source": [
        "import os, string\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import snowballstemmer\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split, cross_val_score \n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import metrics\n",
        "from sklearn.base import BaseEstimator, TransformerMixin"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCHACSPaw-gc"
      },
      "source": [
        "le = LabelEncoder()\n",
        "df['target'] = le.fit_transform(df['CATEGORY'])"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KxYMqxu5xq8j"
      },
      "source": [
        "import re\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "class TextCleaner(BaseEstimator, TransformerMixin):    \n",
        "    def remove_mentions(self, text):        \n",
        "        return re.sub(r'@\\w+', '', text)\n",
        "    \n",
        "    def remove_urls(self, text):        \n",
        "        return re.sub(r'http.?://[^\\s]+[\\s]?', '', text)\n",
        "    \n",
        "    def only_characters(self, text):\n",
        "        return re.sub('[^a-zA-Z\\s]', '', text)\n",
        "    \n",
        "    def remove_extra_spaces(self, text):\n",
        "        text = re.sub(\"\\s+\", ' ', text)\n",
        "        text = text.lstrip()\n",
        "        return text.rstrip()\n",
        "    \n",
        "    def to_lower(self, text):\n",
        "        return text.lower()\n",
        "    \n",
        "    def fix_words(self, text):\n",
        "        text = re.sub(r'\\bthx\\b', 'thanks', text)\n",
        "        text = re.sub(r'\\bu\\b', 'you', text)\n",
        "        text = re.sub(r'\\bhrs\\b', 'hours', text)\n",
        "        text = re.sub(r'\\baa\\b', 'a', text)\n",
        "        text = re.sub(r'\\bflightr\\b', 'flight', text)\n",
        "        text = re.sub(r'\\bur\\b', 'your', text)\n",
        "        text = re.sub(r'\\bhr\\b', 'hour', text)\n",
        "        text = re.sub(r'\\bthru\\b', 'through', text)\n",
        "        text = re.sub(r'\\br\\b', 'are', text)\n",
        "        text = re.sub(r'\\bppl\\b', 'people', text)\n",
        "        text = re.sub(r'\\btix\\b', 'fix', text)\n",
        "        text = re.sub(r'\\bplz\\b', 'please', text)\n",
        "        text = re.sub(r'\\bflightd\\b', 'flighted', text)\n",
        "        text = re.sub(r'\\btmrw\\b', 'tomorrow', text)\n",
        "        text = re.sub(r'\\bthx\\b', 'thanks', text)\n",
        "        text = re.sub(r'\\bpls\\b', 'please', text)\n",
        "        text = re.sub(r'\\bfyi\\b', 'for your information', text)\n",
        "        \n",
        "        text = re.sub(r'\\bheyyyy\\b', 'hey', text)\n",
        "        text = re.sub(r'\\bguyyyys\\b', 'guys', text)\n",
        "        text = re.sub(r'\\byall\\b', 'you all', text)\n",
        "        text = re.sub(r'\\basap\\b', 'as soon as possible', text)\n",
        "        text = re.sub(r'\\bbtw\\b', 'by the way', text)\n",
        "        text = re.sub(r'\\bdm\\b', 'direct message', text)\n",
        "        text = re.sub(r'\\bcudtomers\\b', 'customers', text)\n",
        "        text = re.sub(r'\\bwtf\\b', 'what the fuck', text)\n",
        "        text = re.sub(r'\\biphone\\b', 'phone', text)\n",
        "        text = re.sub(r'\\bmins\\b', 'minutes', text)\n",
        "        text = re.sub(r'\\btv\\b', 'television', text)\n",
        "        text = re.sub(r'\\bokay\\b', 'ok', text)\n",
        "        text = re.sub(r'\\bfeb\\b', 'february', text)\n",
        "        text = re.sub(r'\\byr\\b', 'year', text)\n",
        "        text = re.sub(r'\\bshes\\b', 'she is', text)\n",
        "        text = re.sub(r'\\bnope\\b', 'no', text)\n",
        "        text = re.sub(r'\\bhes\\b', 'he is', text)\n",
        "        text = re.sub(r'\\btill\\b', 'until', text)\n",
        "        text = re.sub(r'\\bomg\\b', 'oh my god', text)\n",
        "        text = re.sub(r'\\btho\\b', 'though', text)\n",
        "        text = re.sub(r'\\bnothappy\\b', 'not happy', text)\n",
        "        return re.sub(r'\\bthankyou\\b', 'thank you', text)\n",
        "        \n",
        "    def fit(self, X, y=None, **fit_params):\n",
        "        return self\n",
        "    \n",
        "    def transform(self, X, **transform_params):        \n",
        "        clean_X = X.apply(self.remove_mentions).apply(self.remove_urls).apply(self.only_characters).apply(self.remove_extra_spaces).apply(self.to_lower).apply(self.fix_words)\n",
        "        return clean_X"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFGl_2RGxUMz"
      },
      "source": [
        "ct = TextCleaner()\n",
        "df['clean_text'] = ct.transform(df['TWEET'])"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S79yjSLexvSk"
      },
      "source": [
        "re_tok = re.compile(f'([{string.punctuation}“”¨«»®´·º½¾¿¡§£₤‘’])')\n",
        "stemmer = snowballstemmer.EnglishStemmer()\n",
        "\n",
        "def tokenize(s): \n",
        "    tokens = re_tok.sub(r' \\1 ', s).split()\n",
        "    return stemmer.stemWords(tokens)"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmXdMYv1x0ns"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(df['clean_text'].values, df['target'].values, test_size=0.25, random_state=0)"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOQ5KVVjx3FU"
      },
      "source": [
        "vect = TfidfVectorizer(strip_accents='unicode', tokenizer=tokenize, ngram_range=(1, 2), max_df=0.75, min_df=3, sublinear_tf=True)"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJK0V2ASx5XT"
      },
      "source": [
        "tfidf_train = vect.fit_transform(X_train)\n",
        "tfidf_test = vect.transform(X_test)"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FY-ajno10P-W",
        "outputId": "e4d07c00-fc44-44e3-92d8-45bb06a4c8ad"
      },
      "source": [
        "z=np.unique(y_train)\n",
        "z\n",
        "\n",
        "lk=z[z!=0]\n",
        "lk\n",
        "tfidf_train[y_train==0].sum(0)"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "matrix([[164.4841382 ,   0.96943109,   0.62992181, ...,   0.        ,\n",
              "           1.21343101,   1.92864503]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmoEtrMCx7S0"
      },
      "source": [
        "def naive_bayes(x, y):\n",
        "    r = []; b = []\n",
        "    labels = np.unique(y)\n",
        "\n",
        "    for l in labels:\n",
        "        other_l = labels[labels != l]\n",
        "        p = x[y == l].sum(0) + 1\n",
        "        # q = x[(y == other_l[0]) | (y == other_l[1])].sum(0) + 1\n",
        "        q = x[(y == other_l[0])].sum(0) + 1\n",
        "        r.append(np.log((p/p.sum())/(q/q.sum())))\n",
        "        b.append(np.log(len(p)/len(q)))\n",
        "    \n",
        "    return r, b"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W51TMhANyD_z"
      },
      "source": [
        "r, b = naive_bayes(tfidf_train, y_train)\n",
        "\n",
        "pre_preds = []\n",
        "for j in range(len(r)):\n",
        "    pre_preds.append(np.asarray(tfidf_test @ r[j].T + b[j]).reshape(-1))\n",
        "arr = np.array(pre_preds)"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wKfbcM881x-8",
        "outputId": "dc8f5422-63f8-4368-bedd-7454cd43f0c5"
      },
      "source": [
        "np.argmax(arr.T, 1)"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 0, ..., 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_pcjDub710hs",
        "outputId": "8f491343-2c19-475f-dc7e-6edb76cf54ed"
      },
      "source": [
        "y_test"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 0, ..., 1, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohQ9OlbEyGZL",
        "outputId": "585020be-5eb6-47ab-e9ee-b981487ece73"
      },
      "source": [
        "metrics.accuracy_score(y_test, np.argmax(arr.T, 1))"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7353191489361702"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "666IFxFU1faM",
        "outputId": "13dc32ff-e516-44b1-dc90-e12f5f21ca76"
      },
      "source": [
        "metrics.f1_score(y_test, np.argmax(arr.T, 1), average='macro')"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6702360078726444"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pLt4ynV2Buo"
      },
      "source": [
        "# Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8dAcoMn2BM7",
        "outputId": "f40fef1a-c1cb-438e-8ed2-d28acd6d56a3"
      },
      "source": [
        "scores = cross_val_score(LogisticRegression(C=2, dual=True), tfidf_train, y_train, cv=5)"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 446, in _check_solver\n",
            "    \"dual=False, got dual=%s\" % (solver, dual))\n",
            "ValueError: Solver lbfgs supports only dual=False, got dual=True\n",
            "\n",
            "  FitFailedWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YcMDQgz81iir",
        "outputId": "2ddd48ea-74e2-4e1f-dff9-c96460eeefdd"
      },
      "source": [
        "scores"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([nan, nan, nan, nan, nan])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gIOtm-7x2LeU",
        "outputId": "b83f24fc-4881-4c08-c538-e0d0ea1a7449"
      },
      "source": [
        "\n",
        "m = LogisticRegression()\n",
        "m.fit(tfidf_train, y_train)"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression()"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FnsRevnh2VYz",
        "outputId": "81d7e669-6418-4a4f-b3a7-14b10173f0e0"
      },
      "source": [
        "preds = m.predict(tfidf_test)\n",
        "(preds==y_test).mean()"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7577304964539007"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZwy6S3Z2rR0",
        "outputId": "8a7de79a-8338-4148-fbaa-e89766a9b0b9"
      },
      "source": [
        "metrics.f1_score(y_test, preds, average='macro')"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6629877265668243"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqAOIx7F2xoM"
      },
      "source": [
        ""
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIZ8N10W2qOM"
      },
      "source": [
        "# BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bo5hmwY12re9",
        "outputId": "1feeb80e-398f-4d61-fb5b-cbf6c0a4c5ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install ktrain"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ktrain in /usr/local/lib/python3.7/dist-packages (0.26.2)\n",
            "Requirement already satisfied: whoosh in /usr/local/lib/python3.7/dist-packages (from ktrain) (2.7.4)\n",
            "Requirement already satisfied: networkx>=2.3 in /usr/local/lib/python3.7/dist-packages (from ktrain) (2.5)\n",
            "Requirement already satisfied: transformers<=4.3.3,>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from ktrain) (4.3.3)\n",
            "Requirement already satisfied: langdetect in /usr/local/lib/python3.7/dist-packages (from ktrain) (1.0.8)\n",
            "Requirement already satisfied: scikit-learn==0.23.2 in /usr/local/lib/python3.7/dist-packages (from ktrain) (0.23.2)\n",
            "Requirement already satisfied: keras-bert>=0.86.0 in /usr/local/lib/python3.7/dist-packages (from ktrain) (0.86.0)\n",
            "Requirement already satisfied: fastprogress>=0.1.21 in /usr/local/lib/python3.7/dist-packages (from ktrain) (1.0.0)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from ktrain) (5.5.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from ktrain) (20.9)\n",
            "Requirement already satisfied: matplotlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from ktrain) (3.2.2)\n",
            "Requirement already satisfied: syntok in /usr/local/lib/python3.7/dist-packages (from ktrain) (1.3.1)\n",
            "Requirement already satisfied: cchardet in /usr/local/lib/python3.7/dist-packages (from ktrain) (2.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from ktrain) (1.0.1)\n",
            "Requirement already satisfied: jieba in /usr/local/lib/python3.7/dist-packages (from ktrain) (0.42.1)\n",
            "Requirement already satisfied: seqeval==0.0.19 in /usr/local/lib/python3.7/dist-packages (from ktrain) (0.0.19)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from ktrain) (0.1.95)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from ktrain) (2.23.0)\n",
            "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from ktrain) (1.1.5)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from networkx>=2.3->ktrain) (4.4.2)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers<=4.3.3,>=4.0.0->ktrain) (0.10.2)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers<=4.3.3,>=4.0.0->ktrain) (3.8.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<=4.3.3,>=4.0.0->ktrain) (3.0.12)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers<=4.3.3,>=4.0.0->ktrain) (0.0.44)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers<=4.3.3,>=4.0.0->ktrain) (4.41.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers<=4.3.3,>=4.0.0->ktrain) (1.19.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<=4.3.3,>=4.0.0->ktrain) (2019.12.20)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from langdetect->ktrain) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.23.2->ktrain) (2.1.0)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.23.2->ktrain) (1.4.1)\n",
            "Requirement already satisfied: Keras>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from keras-bert>=0.86.0->ktrain) (2.4.3)\n",
            "Requirement already satisfied: keras-transformer>=0.38.0 in /usr/local/lib/python3.7/dist-packages (from keras-bert>=0.86.0->ktrain) (0.38.0)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->ktrain) (5.0.5)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.7/dist-packages (from ipython->ktrain) (4.8.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->ktrain) (54.2.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->ktrain) (0.8.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->ktrain) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->ktrain) (1.0.18)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->ktrain) (2.6.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->ktrain) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.0->ktrain) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.0->ktrain) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.0->ktrain) (0.10.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->ktrain) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->ktrain) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->ktrain) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->ktrain) (2.10)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.1->ktrain) (2018.9)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers<=4.3.3,>=4.0.0->ktrain) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers<=4.3.3,>=4.0.0->ktrain) (3.4.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<=4.3.3,>=4.0.0->ktrain) (7.1.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from Keras>=2.4.3->keras-bert>=0.86.0->ktrain) (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from Keras>=2.4.3->keras-bert>=0.86.0->ktrain) (2.10.0)\n",
            "Requirement already satisfied: keras-embed-sim>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from keras-transformer>=0.38.0->keras-bert>=0.86.0->ktrain) (0.8.0)\n",
            "Requirement already satisfied: keras-layer-normalization>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from keras-transformer>=0.38.0->keras-bert>=0.86.0->ktrain) (0.14.0)\n",
            "Requirement already satisfied: keras-pos-embd>=0.11.0 in /usr/local/lib/python3.7/dist-packages (from keras-transformer>=0.38.0->keras-bert>=0.86.0->ktrain) (0.11.0)\n",
            "Requirement already satisfied: keras-position-wise-feed-forward>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from keras-transformer>=0.38.0->keras-bert>=0.86.0->ktrain) (0.6.0)\n",
            "Requirement already satisfied: keras-multi-head>=0.27.0 in /usr/local/lib/python3.7/dist-packages (from keras-transformer>=0.38.0->keras-bert>=0.86.0->ktrain) (0.27.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from traitlets>=4.2->ipython->ktrain) (0.2.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect; sys_platform != \"win32\"->ipython->ktrain) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->ktrain) (0.2.5)\n",
            "Requirement already satisfied: keras-self-attention==0.46.0 in /usr/local/lib/python3.7/dist-packages (from keras-multi-head>=0.27.0->keras-transformer>=0.38.0->keras-bert>=0.86.0->ktrain) (0.46.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWI9XWmw2ueF"
      },
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import ktrain\n",
        "from ktrain import text\n",
        "import tensorflow as tf"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWTSpOZL2w5M",
        "outputId": "d72694d0-24dd-4995-f3e7-c6d916f4bdcd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        }
      },
      "source": [
        "train_df"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TWEET</th>\n",
              "      <th>CATEGORY</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>bono who cares. soon people will understand t...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>eight years the republicans denied obama’s pi...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>get him some line help. he is gonna be just f...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>she is great. hi fiona!</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>she has become a parody unto herself? she has...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11912</th>\n",
              "      <td>i wonder if they are sex traffic victims?</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11913</th>\n",
              "      <td>do we dare say he is better than nyjer?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11914</th>\n",
              "      <td>no idea who he is. sorry</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11915</th>\n",
              "      <td>#professor who shot self over trump says gun c...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11916</th>\n",
              "      <td>here your proof!  our african 🇺🇸 friends do...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11916 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   TWEET  CATEGORY\n",
              "1       bono who cares. soon people will understand t...         0\n",
              "2       eight years the republicans denied obama’s pi...         1\n",
              "3       get him some line help. he is gonna be just f...         0\n",
              "4                               she is great. hi fiona!          0\n",
              "5       she has become a parody unto herself? she has...         1\n",
              "...                                                  ...       ...\n",
              "11912         i wonder if they are sex traffic victims?          1\n",
              "11913           do we dare say he is better than nyjer?          0\n",
              "11914                          no idea who he is. sorry          0\n",
              "11915  #professor who shot self over trump says gun c...         0\n",
              "11916     here your proof!  our african 🇺🇸 friends do...         1\n",
              "\n",
              "[11916 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vB8glU1l433I",
        "outputId": "fbae6b9d-fdc6-4dfa-fad8-8878bb1c4399",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        }
      },
      "source": [
        "(X_train, y_train), (X_test, y_test), preproc = text.texts_from_df(train_df=train_df,\n",
        "                                                                   text_column = 'TWEET',\n",
        "                                                                   label_columns = 'CATEGORY',\n",
        "                                                                   val_df = test_df,\n",
        "                                                                   maxlen = 65,\n",
        "                                                                   preprocess_mode = 'bert')"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['not_CATEGORY', 'CATEGORY']\n",
            "   not_CATEGORY  CATEGORY\n",
            "1           1.0       0.0\n",
            "2           0.0       1.0\n",
            "3           1.0       0.0\n",
            "4           1.0       0.0\n",
            "5           0.0       1.0\n",
            "['not_CATEGORY', 'CATEGORY']\n",
            "   not_CATEGORY  CATEGORY\n",
            "1           0.0       1.0\n",
            "2           1.0       0.0\n",
            "3           1.0       0.0\n",
            "4           1.0       0.0\n",
            "5           1.0       0.0\n",
            "downloading pretrained BERT model (uncased_L-12_H-768_A-12.zip)...\n",
            "[██████████████████████████████████████████████████]\n",
            "extracting pretrained BERT model...\n",
            "done.\n",
            "\n",
            "cleanup downloaded zip...\n",
            "done.\n",
            "\n",
            "preprocessing train...\n",
            "language: en\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "done."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Is Multi-Label? False\n",
            "preprocessing test...\n",
            "language: en\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "done."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00DVZvyL5R01",
        "outputId": "2ea19fa0-4c90-42da-cb3c-24dc83d24cf7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = text.text_classifier(name = 'bert',\n",
        "                             train_data = (X_train, y_train),\n",
        "                             preproc = preproc)"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Is Multi-Label? False\n",
            "maxlen is 65\n",
            "done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqNc7gbB5gXs"
      },
      "source": [
        "learner = ktrain.get_learner(model=model, train_data=(X_train, y_train),\n",
        "                   val_data = (X_test, y_test),\n",
        "                   batch_size = 6)"
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyHljF-x5pO1",
        "outputId": "13cefb15-3379-4d1b-b2c5-3ed4a318e0a8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "learner.fit_onecycle(lr = 2e-5, epochs = 1)\n",
        "\n",
        "predictor = ktrain.get_predictor(learner.model, preproc)\n",
        "predictor.save('/content/drive/My Drive/bert')"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "begin training using onecycle policy with max lr of 2e-05...\n",
            "1986/1986 [==============================] - 596s 293ms/step - loss: 0.5492 - accuracy: 0.7196 - val_loss: 0.3599 - val_accuracy: 0.8628\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhVcadQF5wMN"
      },
      "source": [
        "data = test_df['TWEET'].tolist()"
      ],
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sIXbPUu98Zvs"
      },
      "source": [
        "bert_pred=predictor.predict(data)"
      ],
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ea3_Zbvz8bOg",
        "outputId": "e90d0e39-82d1-4130-e254-4427ecdefef5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "bert_pred[5:10]"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['not_CATEGORY', 'not_CATEGORY', 'not_CATEGORY', 'CATEGORY', 'CATEGORY']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITZIRUEw9dwD"
      },
      "source": [
        "y_true=np.array(test_df['CATEGORY'].tolist())"
      ],
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_trKiRh-9lLN"
      },
      "source": [
        "res_bert=[]\n",
        "for i in range(len(bert_pred)):\n",
        "  if bert_pred[i]=='CATEGORY':\n",
        "    res_bert.append(1)\n",
        "  else:\n",
        "    res_bert.append(0)"
      ],
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPuSutit94Dx"
      },
      "source": [
        "res_bert=np.array(res_bert)"
      ],
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztXD4k4y98L9",
        "outputId": "ece4c6d6-6334-41f4-cd23-41a4d69cc918",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "np.mean(res_bert==y_true)"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8627906976744186"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ZCpcjNHA-EG",
        "outputId": "76651fd8-3d71-4f35-cbe2-d8fe33ecd56b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "metrics.f1_score(y_true, res_bert, average='macro')"
      ],
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8263411161536303"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hoWF6yCQCYgM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}