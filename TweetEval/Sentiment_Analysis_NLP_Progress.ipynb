{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment_Analysis_NLP_Progress.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prawizard/TweetsClassification_NLP/blob/main/TweetEval/Sentiment_Analysis_NLP_Progress.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zxm9gIFFi02"
      },
      "source": [
        "# Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pD7oNRf_BCiU"
      },
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import urllib.request\n",
        "import nltk\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import SnowballStemmer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.metrics import f1_score\n",
        "import requests\n",
        "import collections"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgN_9rGQyena"
      },
      "source": [
        "\n",
        "import os, string, collections\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import snowballstemmer\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
        "from sklearn import metrics\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential, Model, load_model\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.layers import Flatten, Dense, Dropout, Convolution1D, MaxPooling1D, SpatialDropout1D, Input \n",
        "from keras.layers import GlobalMaxPooling1D, concatenate, LSTM, Bidirectional\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import np_utils\n",
        "from keras.callbacks import ModelCheckpoint"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDKThEBPVrEE"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,Flatten,Embedding,Activation, Dropout\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, GlobalMaxPooling1D \n",
        "import numpy as np\n",
        "from numpy import array\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GT7sQy4ZFttE"
      },
      "source": [
        "# Constants"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MlB9kkYFFotD"
      },
      "source": [
        "TRAIN_TEXT_URL=\"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/offensive/train_text.txt\"\n",
        "TRAIN_LABELS_URL=\"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/offensive/train_labels.txt\"\n",
        "VAL_TEXT_URL=\"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/offensive/val_text.txt\"\n",
        "VAL_LABELS_URL=\"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/offensive/val_labels.txt\"\n",
        "TEST_TEXT_URL=\"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/offensive/test_text.txt\"\n",
        "TEST_LABELS_URL=\"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/offensive/test_labels.txt\"\n",
        "VOCAB_SIZE=2000"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igvM4blPFz8b"
      },
      "source": [
        "# Access Data from the Files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhTRYuieF-LC"
      },
      "source": [
        "## Download the .txt files to our runtime"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3eP1mSZRFpBF",
        "outputId": "4326a989-fd49-45ba-8f42-0cb835712c66"
      },
      "source": [
        "r = requests.get(TRAIN_TEXT_URL, allow_redirects=True)\n",
        "open('train_text.txt', 'wb').write(r.content)\n",
        "\n",
        "r = requests.get(TRAIN_LABELS_URL, allow_redirects=True)\n",
        "open('train_labels.txt', 'wb').write(r.content)\n",
        "\n",
        "r = requests.get(VAL_TEXT_URL, allow_redirects=True)\n",
        "open('val_text.txt', 'wb').write(r.content)\n",
        "\n",
        "r = requests.get(VAL_LABELS_URL, allow_redirects=True)\n",
        "open('val_labels.txt', 'wb').write(r.content)\n",
        "\n",
        "r = requests.get(TEST_TEXT_URL, allow_redirects=True)\n",
        "open('test_text.txt', 'wb').write(r.content)\n",
        "\n",
        "r = requests.get(TEST_LABELS_URL, allow_redirects=True)\n",
        "open('test_labels.txt', 'wb').write(r.content)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1720"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgJlnjLsGPHE"
      },
      "source": [
        "## Read data from the files downloaded"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewS1DCGvFpHb"
      },
      "source": [
        "# Tweets\n",
        "stream=open(\"train_text.txt\")\n",
        "tweets=stream.readlines()\n",
        "stream.close()\n",
        "val_stream=open(\"val_text.txt\")\n",
        "val_tweets=val_stream.readlines()\n",
        "val_stream.close()\n",
        "test_stream=open(\"test_text.txt\")\n",
        "test_tweets=test_stream.readlines()\n",
        "test_stream.close()\n",
        "\n",
        "# Labels\n",
        "stream=open(\"train_labels.txt\")\n",
        "tweetsLabels=stream.readlines()\n",
        "stream.close()\n",
        "val_stream=open(\"val_labels.txt\")\n",
        "val_tweetsLabels=val_stream.readlines()\n",
        "val_stream.close()\n",
        "test_stream=open(\"test_labels.txt\")\n",
        "test_tweetsLabels=test_stream.readlines()\n",
        "test_stream.close()\n",
        "\n",
        "\n",
        "# Labels\n",
        "labels=[0]*len(tweetsLabels)\n",
        "for i in range(len(tweetsLabels)):\n",
        "  if tweetsLabels[i].find('\\n')!=-1:\n",
        "    labels[i]=int(re.sub('\\n', '', tweetsLabels[i]))\n",
        "val_labels=[0]*len(val_tweetsLabels)\n",
        "for i in range(len(val_tweetsLabels)):\n",
        "  if val_tweetsLabels[i].find('\\n')!=-1:\n",
        "    val_labels[i]=int(re.sub('\\n', '', val_tweetsLabels[i]))\n",
        "test_labels=[0]*len(test_tweetsLabels)\n",
        "for i in range(len(test_tweetsLabels)):\n",
        "  if test_tweetsLabels[i].find('\\n')!=-1:\n",
        "    test_labels[i]=int(re.sub('\\n', '', test_tweetsLabels[i]))\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jh8aZrlQFpNM",
        "outputId": "c6b89878-23b8-4fba-d4d2-289d92746c36"
      },
      "source": [
        "print('Samples in Training set : ',len(labels),', Validation set : ', len(val_labels),', Test set : ', len(test_labels))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Samples in Training set :  11916 , Validation set :  1324 , Test set :  860\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTbHMhp-JxUk"
      },
      "source": [
        "# Pre-processing of the text in tweets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7z2JpSWKK3b"
      },
      "source": [
        "## Remove the '@User' text parts from tweets\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ND7rNLwzJ5gm"
      },
      "source": [
        "\n",
        "for i in range(len(tweets)):\n",
        "  if tweets[i].find('@user')!=-1:\n",
        "    tweets[i]=re.sub('@user', '', tweets[i])\n",
        "\n",
        "for i in range(len(val_tweets)):\n",
        "  if val_tweets[i].find('@user')!=-1:\n",
        "    val_tweets[i]=re.sub('@user', '', val_tweets[i])\n",
        "\n",
        "for i in range(len(test_tweets)):\n",
        "  if test_tweets[i].find('@user')!=-1:\n",
        "    test_tweets[i]=re.sub('@user', '', test_tweets[i])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CgqCpZNSKW_0"
      },
      "source": [
        "## Remove hashtags"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3hXCHYWMJ5d7"
      },
      "source": [
        "for i in range(len(tweets)):\n",
        "  if tweets[i].find('#[a-zA-Z]+')!=-1:\n",
        "    tweets[i]=re.sub('#[a-zA-Z]+', '', tweets[i])\n",
        "\n",
        "for i in range(len(val_tweets)):\n",
        "  if val_tweets[i].find('#[a-zA-Z]+')!=-1:\n",
        "    val_tweets[i]=re.sub('#[a-zA-Z]+', '', val_tweets[i])\n",
        "\n",
        "for i in range(len(test_tweets)):\n",
        "  if test_tweets[i].find('#[a-zA-Z]+')!=-1:\n",
        "    test_tweets[i]=re.sub('#[a-zA-Z]+', '', test_tweets[i])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3lvlpSpLW11"
      },
      "source": [
        "## Remove escape characters, unnecessary characters if present and correct wrongly spelt words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pY-TDJ8WJ5ar"
      },
      "source": [
        "for i in range(len(tweets)):\n",
        "  if tweets[i].find('\\n')!=-1:\n",
        "    tweets[i]=re.sub('\\n', '', tweets[i])\n",
        "\n",
        "for i in range(len(val_tweets)):\n",
        "  if val_tweets[i].find('\\n')!=-1:\n",
        "    val_tweets[i]=re.sub('\\n', '', val_tweets[i])\n",
        "\n",
        "for i in range(len(test_tweets)):\n",
        "  if test_tweets[i].find('\\n')!=-1:\n",
        "    test_tweets[i]=re.sub('\\n', '', test_tweets[i])\n",
        "\n",
        "# Unnecessary dots\n",
        "p='\\.\\.\\.|\\.\\.'\n",
        "\n",
        "for i in range(len(tweets)):\n",
        "  tweets[i]=re.sub(p, '', tweets[i])\n",
        "  tweets[i]=tweets[i].lower()\n",
        "\n",
        "for i in range(len(val_tweets)):\n",
        "  val_tweets[i]=re.sub(p, '', val_tweets[i])\n",
        "  val_tweets[i]=val_tweets[i].lower()\n",
        "\n",
        "for i in range(len(test_tweets)):\n",
        "  test_tweets[i]=re.sub(p, '', test_tweets[i])\n",
        "  test_tweets[i]=test_tweets[i].lower()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPK6DFYJai3p"
      },
      "source": [
        "rows=[]\n",
        "rowIndices=[]\n",
        "for i in range(len(tweets)):\n",
        "  rows.append({\"TWEET\":tweets[i], \"CATEGORY\":labels[i]})\n",
        "  rowIndices.append(i+1)\n",
        "df=pd.DataFrame(rows, index=rowIndices)\n",
        "\n",
        "val_rows=[]\n",
        "val_rowIndices=[]\n",
        "for i in range(len(val_tweets)):\n",
        "  val_rows.append({\"TWEET\":val_tweets[i], \"CATEGORY\":val_labels[i]})\n",
        "  val_rowIndices.append(i+1)\n",
        "val_df=pd.DataFrame(val_rows, index=val_rowIndices)\n",
        "\n",
        "test_rows=[]\n",
        "test_rowIndices=[]\n",
        "for i in range(len(test_tweets)):\n",
        "  test_rows.append({\"TWEET\":test_tweets[i], \"CATEGORY\":test_labels[i]})\n",
        "  test_rowIndices.append(i+1)\n",
        "test_df=pd.DataFrame(test_rows, index=test_rowIndices)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MstYIClUev7S"
      },
      "source": [
        "frames=[df, val_df, test_df]\n",
        "df=pd.concat(frames)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nC7x0RmBaiyJ",
        "outputId": "078d3f78-055a-46ef-fa88-d678183bedbb"
      },
      "source": [
        "type(df)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.frame.DataFrame"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "cXse8yQ8aiva",
        "outputId": "9fdc698e-f0a8-42cd-ee4b-975b5e75825b"
      },
      "source": [
        "df"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TWEET</th>\n",
              "      <th>CATEGORY</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>bono who cares. soon people will understand t...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>eight years the republicans denied obama’s pi...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>get him some line help. he is gonna be just f...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>she is great. hi fiona!</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>she has become a parody unto herself? she has...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>856</th>\n",
              "      <td>#cnn irrationally argues 4 legalising #abortio...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>857</th>\n",
              "      <td>city of chicago, democrat run wi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>858</th>\n",
              "      <td>#conservatives don’t care what you postit’s  p...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>859</th>\n",
              "      <td>#antifa #resist trump is trying to bring world...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>860</th>\n",
              "      <td>#maine you need to face facts  doesn’t really ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>14100 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 TWEET  CATEGORY\n",
              "1     bono who cares. soon people will understand t...         0\n",
              "2     eight years the republicans denied obama’s pi...         1\n",
              "3     get him some line help. he is gonna be just f...         0\n",
              "4                             she is great. hi fiona!          0\n",
              "5     she has become a parody unto herself? she has...         1\n",
              "..                                                 ...       ...\n",
              "856  #cnn irrationally argues 4 legalising #abortio...         0\n",
              "857                city of chicago, democrat run wi...         0\n",
              "858  #conservatives don’t care what you postit’s  p...         1\n",
              "859  #antifa #resist trump is trying to bring world...         0\n",
              "860  #maine you need to face facts  doesn’t really ...         0\n",
              "\n",
              "[14100 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bwk0QJELaisS",
        "outputId": "75231569-431e-4bfc-bbd1-3e44a6a57405"
      },
      "source": [
        "df['CATEGORY'].value_counts()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    9460\n",
              "1    4640\n",
              "Name: CATEGORY, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GaFjjNEdaikK",
        "outputId": "0b2dfecd-5a8a-4d47-8db8-1585e3555d96"
      },
      "source": [
        "text = df['TWEET'].tolist()\n",
        "text[:10]"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[' bono who cares. soon people will understand that they gain nothing from following a phony celebrity. become a leader of your people instead or help and support your fellow countrymen. ',\n",
              " ' eight years the republicans denied obama’s picks. breitbarters outrage is as phony as their fake president. ',\n",
              " ' get him some line help. he is gonna be just fine. as the game went on you could see him progressing more with his reads. he brought what has been missing. the deep ball presence. now he just needs a little more time ',\n",
              " '  she is great. hi fiona! ',\n",
              " \" she has become a parody unto herself? she has certainly taken some heat for being such an.well idiot. could be optic too  who know with liberals  they're all optics.  no substance \",\n",
              " '               this is the vetsresistsquadron\"\" is bullshit they are girl scout veterans, i have never met any other veterans or served with anyone that was a gun control advocate? have you?\"\" ',\n",
              " ' your looking more like a plant #maga #walkaway ',\n",
              " '  lol. except he’s the most successful president in our lifetimes. he’s undone most of the damage obummer did and set america on the right path again. #maga ',\n",
              " ' been a willie fan since before most of you were born.love that he is holding a rally with beto. exactly which fans are furious?  could you give some specifics? ',\n",
              " \" here's a link to my channel with a plethora of topics to peruse: \"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9EYIcwqdLd-"
      },
      "source": [
        "y = df['CATEGORY']"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ZvX83DbdLjq",
        "outputId": "1e009df9-2b9e-401c-e68e-66ec80315379"
      },
      "source": [
        "token = Tokenizer()\n",
        "token.fit_on_texts(text)\n",
        "token"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras_preprocessing.text.Tokenizer at 0x7fc3433ea2d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oeT9J6pfdLqK",
        "outputId": "84986014-f744-4296-de03-f217f2fbb753"
      },
      "source": [
        "vocab_size = len(token.word_index) + 1\n",
        "vocab_size"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23433"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nek6_FDzdLwT",
        "outputId": "fc6cb501-5984-4a2f-f09c-9a0b42bff701"
      },
      "source": [
        "import itertools \n",
        "print(dict(itertools.islice(token.index_word.items(), 100)))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{1: 'the', 2: 'is', 3: 'to', 4: 'a', 5: 'and', 6: 'you', 7: 'of', 8: 'are', 9: 'i', 10: 'he', 11: 'in', 12: 'that', 13: 'for', 14: 'she', 15: 'it', 16: 'this', 17: 'on', 18: 'not', 19: 'with', 20: 'they', 21: 'have', 22: 'be', 23: 'liberals', 24: 'gun', 25: 'so', 26: 'all', 27: 'control', 28: 'antifa', 29: 'your', 30: 'like', 31: 'what', 32: 'as', 33: 'but', 34: 'we', 35: 'just', 36: 'about', 37: 'her', 38: 'maga', 39: 'was', 40: 'if', 41: 'conservatives', 42: 'will', 43: 'do', 44: 'who', 45: 'people', 46: 'no', 47: 'his', 48: 'at', 49: 'or', 50: 'my', 51: 'by', 52: 'has', 53: 'from', 54: 'how', 55: 'an', 56: 'out', 57: 'up', 58: 'their', 59: 'me', 60: 'get', 61: 'one', 62: 'amp', 63: 'know', 64: 'trump', 65: 'why', 66: 'when', 67: 'more', 68: 'because', 69: 'can', 70: 'him', 71: 'now', 72: 'them', 73: 'think', 74: \"don't\", 75: 'there', 76: 'would', 77: 'should', 78: 'right', 79: 'our', 80: 'good', 81: 'only', 82: 'us', 83: \"it's\", 84: 'want', 85: 'time', 86: 'go', 87: 'see', 88: 'going', 89: 'need', 90: 'never', 91: 'than', 92: 'shit', 93: 'been', 94: 'being', 95: 'don’t', 96: 'then', 97: 'love', 98: 'even', 99: 'these', 100: 'say'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_7w-lgcdL1t",
        "outputId": "9e1a0306-5b1a-4244-980f-7fb9644f19e0"
      },
      "source": [
        "x = ['i to the a and']\n",
        "token.texts_to_sequences(x)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[9, 3, 1, 4, 5]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LxGkvfuldL7G",
        "outputId": "57d9a198-056f-4ff7-9808-2a1a437dcaa1"
      },
      "source": [
        "encoded_text = token.texts_to_sequences(text)\n",
        "print(encoded_text[:30])"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1370, 44, 694, 532, 45, 42, 324, 12, 20, 1923, 145, 53, 542, 4, 2279, 3978, 437, 4, 660, 7, 29, 45, 480, 49, 182, 5, 159, 29, 1638, 10016], [3979, 147, 1, 263, 4601, 2875, 3980, 10017, 1566, 2, 32, 2279, 32, 58, 285, 135], [60, 70, 107, 543, 182, 10, 2, 415, 22, 35, 517, 32, 1, 298, 544, 17, 6, 154, 87, 70, 10018, 67, 19, 47, 10019, 10, 1125, 31, 52, 93, 1371, 1, 569, 2021, 3501, 71, 10, 35, 224, 4, 287, 67, 85], [14, 2, 138, 1208, 3981], [14, 52, 437, 4, 6990, 10020, 746, 14, 52, 1372, 850, 107, 5520, 13, 94, 188, 55, 117, 570, 154, 22, 10021, 102, 44, 63, 19, 23, 361, 26, 5521, 46, 6991], [16, 2, 1, 10022, 2, 533, 20, 8, 362, 10023, 2022, 9, 21, 90, 1080, 101, 118, 2022, 49, 2639, 19, 213, 12, 39, 4, 24, 27, 1924, 21, 6], [29, 288, 67, 30, 4, 2876, 38, 352], [161, 586, 260, 1, 119, 1253, 135, 11, 79, 10024, 260, 6992, 119, 7, 1, 2133, 10025, 105, 5, 639, 174, 17, 1, 78, 2431, 158, 38], [93, 4, 3127, 649, 220, 204, 119, 7, 6, 110, 1126, 97, 12, 10, 2, 1081, 4, 1209, 19, 951, 368, 185, 980, 8, 1567, 154, 6, 192, 107, 6993], [2280, 4, 1568, 3, 50, 2877, 19, 4, 10026, 7, 3502, 3, 10027], [28, 76, 1425, 4, 41, 397, 128, 5, 599, 76, 22, 75, 10028, 1, 10029, 62, 1639, 2640, 17, 1, 5522], [20, 6994, 1827, 94, 1210, 13, 3982, 10030, 6995, 75, 8, 827, 10031, 2878, 1, 155, 40, 18, 628, 342, 7, 92, 40, 6, 8, 88, 3, 390, 1, 213, 69, 60, 1210, 1496, 1640, 99, 45, 123, 2641, 5523, 5, 5524, 10032], [545, 4602, 554, 2642, 7, 3503, 5, 96, 300, 3, 3128, 112, 24, 27, 450, 197, 1569], [10033], [2643, 77, 21, 93, 1321, 112, 4, 245, 348, 301, 30, 1, 1735, 42, 222, 70, 6996, 1, 3983, 78, 148, 1, 6997, 221, 117], [16, 2, 4, 447, 1082, 53, 23, 5, 113, 294, 3129, 2432, 34, 21, 3, 2879, 1, 650, 184, 4603, 253, 184, 5, 96, 3504, 87, 922, 11, 15, 10034], [123, 10035, 2644, 119, 7, 1, 10036, 1211, 124, 194, 506, 12, 17, 59], [117, 87, 40, 9, 273, 264, 48, 2281, 36, 902, 24, 27, 167, 5, 14, 3984, 59, 49, 775, 59, 4, 3505, 2433, 10037, 2880, 32, 14, 105, 96, 34, 600, 322, 4, 1641, 127, 35, 264, 148, 1, 5525], [6, 241, 1, 103, 523, 1083, 10038, 26, 7, 2023, 2881], [138, 2882, 75, 599, 243, 18, 25, 114, 38, 10039], [6, 8, 25, 10040, 15, 239, 22, 281, 3, 373, 12, 103], [26, 6, 43, 2, 357, 26, 534, 122, 82, 357, 38], [10041, 3985], [10, 123, 10042, 12, 75, 2, 1, 1164, 2134, 66, 34, 8, 2434, 1126, 96, 75, 2, 1, 6998, 2134, 185, 2, 728, 66, 34, 10043, 828, 3, 79, 4604, 6999, 5, 22, 10044, 10045, 160, 94, 7000, 51, 47, 2024, 48, 7001, 66, 79, 4605, 1642, 2, 470, 3506, 187], [65, 8, 6, 2282, 85, 7002, 17, 259, 3986, 17, 2883, 7, 45, 289, 335, 12, 1497, 387, 30, 208, 2, 35, 4, 1007, 10046, 1322, 10047, 3, 118, 5526, 12, 20, 172, 2645, 51, 64], [34, 115, 10048, 2646, 587, 1, 3130, 747, 33, 34, 69, 2647, 729, 13, 66, 10, 1165, 47, 198, 1008, 39, 5527, 10049, 2884, 2283, 54, 36, 1570, 5, 16, 2, 10050, 195, 245, 1040, 5, 10, 2, 1040, 114, 121, 91, 1570], [14, 2, 4, 223, 1426, 9, 178, 37, 25, 114], [10, 2, 25, 3987, 5, 9, 97, 54, 1254, 10, 2, 32, 4, 230], [1166, 34, 639, 96, 291], [10, 2, 4, 10051, 1167, 10]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5TyYMOtpdvYc",
        "outputId": "4020df43-91de-489f-858c-1178fa2f52c8"
      },
      "source": [
        "ll=len(encoded_text[0])\n",
        "for tw in encoded_text:\n",
        "  l=len(tw)\n",
        "  if l>ll:\n",
        "    ll=l\n",
        "ll"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "62"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8hQLwOKVdMAf",
        "outputId": "0e3febc0-375e-42b6-f6b5-6e0c19148a4c"
      },
      "source": [
        "max_length = 65\n",
        "X = pad_sequences(encoded_text, maxlen=max_length, padding='post')\n",
        "print(X)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1370   44  694 ...    0    0    0]\n",
            " [3979  147    1 ...    0    0    0]\n",
            " [  60   70  107 ...    0    0    0]\n",
            " ...\n",
            " [  41   95  184 ...    0    0    0]\n",
            " [  28  888   64 ...    0    0    0]\n",
            " [9691    6   89 ...    0    0    0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fvtoeqHTdMF5",
        "outputId": "425c86c0-5a86-44e5-cf1d-ab501b3a83bc"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14100, 65)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IiKGYgHyfwej"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42, test_size = 0.2, stratify = y)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "059Elzdkfwkg"
      },
      "source": [
        "vec_size = 350\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, vec_size, input_length=max_length))\n",
        "\n",
        "model.add(Conv1D(64, 8, activation = 'relu'))\n",
        "model.add(MaxPooling1D(2))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(16, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(GlobalMaxPooling1D())\n",
        "\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-k_-mQRyfwo9"
      },
      "source": [
        "model.compile(optimizer='adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DdvlqqS_fwsy",
        "outputId": "5b66b75e-03e6-4b41-d94b-cfdd767a321d"
      },
      "source": [
        "%%time\n",
        "model.fit(X_train, y_train, epochs = 5, validation_data = (X_test, y_test))"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "353/353 [==============================] - 30s 82ms/step - loss: 0.6366 - accuracy: 0.6600 - val_loss: 0.5828 - val_accuracy: 0.7348\n",
            "Epoch 2/5\n",
            "353/353 [==============================] - 29s 81ms/step - loss: 0.4771 - accuracy: 0.7912 - val_loss: 0.5584 - val_accuracy: 0.7408\n",
            "Epoch 3/5\n",
            "353/353 [==============================] - 29s 81ms/step - loss: 0.3088 - accuracy: 0.8837 - val_loss: 0.5559 - val_accuracy: 0.7355\n",
            "Epoch 4/5\n",
            "353/353 [==============================] - 29s 82ms/step - loss: 0.1933 - accuracy: 0.9328 - val_loss: 0.6302 - val_accuracy: 0.7191\n",
            "Epoch 5/5\n",
            "353/353 [==============================] - 29s 81ms/step - loss: 0.1155 - accuracy: 0.9630 - val_loss: 0.7487 - val_accuracy: 0.7262\n",
            "CPU times: user 4min 4s, sys: 6.99 s, total: 4min 11s\n",
            "Wall time: 2min 24s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc2ef1ed050>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYc-KEDTi2B0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}